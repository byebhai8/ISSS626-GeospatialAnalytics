{
  "hash": "9c50c90a533d2a8d1bcaee037a08150f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"In-Class Exercise 10\"\nauthor: \"Bhairavi Vairavelu\"\ndate: \"Nov 09 2024\"\ndate-modified: \"last-modified\"\nexecute:\n  eval: true\n  echo: true\n  message: false\n  freeze: true\n---\n\n\n# Working with Open Government Data\n\n## 1. Learning Outcome\n\nIn this exercise, we will:\n\n-   Prepare data downloaded from REALIS portal for geocoding\n\n-   Geocode using SLA OneMap API\n\n-   Covert the geocoded transaction data into sf point feature data.frame\n\n-   Wrangle the sf point features to avoid overlapping point features\n\n## 2. Loading R Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(tidyverse, sf, tmap, httr, performance)\n```\n:::\n\n\n## 3. Importing the Data\n\nThe code chunk below imports multiple csv files in a specific folder and appends them into a single tibble data frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfolder_path <- \"data/aspatial\"\nfile_list <- list.files(path = folder_path, \n                        pattern = \"^ResidentialTransaction.*\\\\.csv$\", \n                        full.names = TRUE)\n\nrealis_data <- file_list %>%\n  map_dfr(read_csv)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 10000 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (15): Project Name, Sale Date, Address, Type of Sale, Type of Area, Nett...\ndbl  (2): Area (SQM), Number of Units\nnum  (4): Transacted Price ($), Area (SQFT), Unit Price ($ PSF), Unit Price ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 6669 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (15): Project Name, Sale Date, Address, Type of Sale, Type of Area, Nett...\ndbl  (2): Area (SQM), Number of Units\nnum  (4): Transacted Price ($), Area (SQFT), Unit Price ($ PSF), Unit Price ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n## 4. Wrangling the Data\n\nThe code chunk below performs the following:\n\n-   Converts values in Sale Date field from character to numerical date format\n\n-   Extracts resale and condo transaction records\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncondo_resale <- realis_data %>%\n  mutate(`Sale Date` = dmy(`Sale Date`)) %>%\n  filter(`Type of Sale` == \"Resale\" &\n           `Property Type` == \"Condominium\")\n```\n:::\n\n\n## 5. Geocoding\n\nWe will use the code chunk below to prepare the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npostcode <- unique(condo_resale$`Postal Code`)\n```\n:::\n\n\nNext, the code chunk below will be used to perform geocoding:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurl <- \"https://onemap.gov.sg/api/common/elastic/search\"\nfound <- data.frame()\nnot_found <- data.frame()\n\nfor (postcode in postcode){\n  query <- list('searchVal'=postcode, 'returnGeom'='Y', \n                'getAddrDetails'='Y', 'pageNum'='1')\n  res <- GET(url, query=query)\n  if ((content(res)$found)!=0){\n    found <- rbind(found, data.frame(content(res))[4:13])\n  } else {not_found = data.frame(postcode)\n  }\n}\n```\n:::\n\n\nWe can clean up the field names using the code chunk below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfound <- found %>%\n  select(c(6:8)) %>%\n  rename(POSTAL = `results.POSTAL`,\n         XCOORD = `results.X`,\n         YCOORD = `results.Y`)\n```\n:::\n\n\n## 6. Converting to Point Feature Data Frame\n\nThe code chunk below will join the condo_reslae and found tables and save it as condo_reslae_geocoded:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncondo_resale_geocoded = left_join(\n  condo_resale, found, \n  by = c('Postal Code' = 'POSTAL'))\n```\n:::\n\n\nNext, we will use the code chunk below to convert condo_reslae_geocoded from tibble data frame to sf point feature date frame:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncondo_resale_sf <- st_as_sf(condo_resale_geocoded, \n                            coords = c(\"XCOORD\",\n                                       \"YCOORD\"),\n                            crs=3414)\n```\n:::\n\n\nWe can also clean up the spatial data by checking if there are overlapping point features, as shown in the code chunk below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\noverlapping_points <- condo_resale_sf %>%\n  mutate(overlap = lengths(st_equals(., .)) > 1)\n```\n:::\n\n\nIn the code chunk below, st_jitter() of sf package is used to move the point features by 5m to avoid overlapping point features:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncondo_resale_sf <- condo_resale_sf %>%\n  st_jitter(amount = 2)\n```\n:::\n\n\nx\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}