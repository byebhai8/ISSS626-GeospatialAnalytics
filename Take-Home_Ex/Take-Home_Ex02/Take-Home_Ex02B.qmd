---
title: "Take-Home Exercise 02"
author: "Bhairavi Vairavelu"
date: "Sep 30 2024"
date-modified: "last-modified"
execute:
  eval: true
  echo: true
  message: false
  freeze: true
---

# Discovering Impacts of COVID-19 on Thailand Tourism Economy using Spatial & Spatio-Temporal Statistics

## 1.0 Overview

Tourism is one of Thailandâ€™s largest industries, accounting for some 20% of the gross domestic product (GDP). In 2019, Thailand earned 90 billion US\$ from domestic and international tourism, but the COVID-19 pandemic caused revenues to crash to 24 billion US\$ in 2020.

The revenue from tourism industry have been recovered gradually since September 2021. However, it is important to note that the tourism economy of Thailand are not evenly distributed. Note that the tourism economy of Thailand are mainly focused on five provinces, namely Bangkok, Phuket, Chon Buri, Krabi and Chiang Mai.

### 1.1 Objectives

Through this exercise, we are interested to discover the following:

-   If the key indicators of tourism economy of Thailand are independent from space and space and time

-   If the tourism economy is indeed spatial and spatio-temporal dependent

    -   If so, we would like to detect where are the clusters and outliers, and the emerging hot spot/cold spot areas

### 1.2 The Task

We will be performing the following tasks in this exercise:

-   Preparation of the following Geospatial data layer:

    -   Study area layer in sf polygon features (at province level incl. Bangkok)

    -   Tourism economy indicators layer within the study area in sf polygon features

    -   Derived tourism economy indicator layer in spacetime s3 class of sfdep, with time series kept at month and year levels

-   Perform Global Spatial Autocorrelation Analysis using sfdep methods

-   Perform Local Spatial Autocorrelation Analysis using sfdep methods

-   Perform Emerging Hot/Cold Spot Analysis using sfdep methods

### 1.3 Analytical Tools

The following R packages will be used for this exercise:

-   **sf**, which is used for importing and handling geospatial data in R

-   **sfdep**, which is used for spatial dependence with spatial features

-   **tmap**, which is used to prepare cartographic quality choropleth maps

-   **plotly**, for creating interactive graphs

-   **tidyverse**, which is mainly for wrangling attribute data in R

-   **lubridate**, which is used to parse and manipulate dates

-   **Kendall**, which helps compute the Kendall rank correlation and Mann-Kendall trend test

The code chunk below uses p_load() of pacman package to check if the necessary packages have been installed in R. If yes, we will load the packages on R environment as shown below.

```{r}
pacman::p_load(sf, sfdep, tmap, plotly, tidyverse, lubridate, Kendall)
```

## 2.0 Data

### 2.1 Getting the Data

For this exercise, we will be using two datasets:

-   Thailand Domestic Tourism Statistics from Kaggle (Version 2)

![](data01.png){fig-align="center"}

-   Thailand - Subnational Administrative Boundaries from HDX

![](data02.png){fig-align="center"}

### 2.2 Importing the Data

These are the files we have for Thailand Domestic Tourism Statistics:

![](data01_files.png){fig-align="center"}

Note that we will only use Version 2 of the dataset.

The code chunk below is used to load the ver2 data into our R environment.

```{r}
#|eval: false
tourism <- read_csv("data/aspatial/thailand_domestic_tourism_2019_2023_ver2.csv")
write_rds(tourism, "data/rds/tourism.rds")
```

The code chunk below will be used to import the saved tourism.rds into R environment.

```{r}
tourism <- read_rds("data/rds/tourism.rds")
```

These are the files we have for Thailand - Subnational Administrative Boundaries:

![](data02_files.png){fig-align="center"}

Recall that this HDX data source contains information on 4 administrative levels - 0 for Country, 1 for Province, 2 for District and 3 for Sub-District. Hence, there were numerous files downloaded from this data source. However, we only want to focus on Province-level analysis for this exercises. As such, we will only load the ADM1 data into our R environment.

The code chunk below is used to load the ver2 data into our R environment.

```{r}
#|eval: false
boundaries = st_read(dsn = "data/geospatial",
                     layer = "tha_admbnda_adm1_rtsd_20220121")
write_rds(boundaries, "data/rds/boundaries.rds")
```

The code chunk below will be used to import the saved boundaries.rds into R environment.

```{r}
boundaries <- read_rds("data/rds/boundaries.rds")
```

## 3.0 Data Wrangling

### 3.1 Tourism Data

Let's take a quick look at the newly imported tourism data by using the glimpse() function of dplyr package as shown below.

```{r}
glimpse(tourism)
```

The raw tourism data has 30,800 rows and 7 columns. This data will serve as the attribute table that we will use moving forward.

Now, we will perform following actions using the code chunk below:

-   Exclude fields that contain text in thai language - province_thai, region_thai

-   Create new fields for month and year using the existing date field

-   Unpivot the variable & value columns to expose new fields for our analysis

-   Convert revenue fields to be shown in the thousands

-   Rename fields to a more appropriate name

```{r}
tourism <- tourism %>%
  select(1,3,5,6,7) %>%
  mutate(month = month(date, label = TRUE, abbr = TRUE),
         year = year(date)) %>%
  pivot_wider(names_from = variable,
              values_from = value) %>%
  mutate(revenue_all = revenue_all/1000,
         revenue_thai = revenue_thai/1000,
         revenue_foreign = revenue_foreign/1000) %>%
  rename(province = province_eng,
         region = region_eng,
         revenue_all_K = revenue_all,
         revenue_thai_K = revenue_thai,
         revenue_foreign_K = revenue_foreign)
```

Let's take a look at the cleaned up tourism data set:

```{r}
glimpse(tourism)
```

The updated tourism data has 3,850 rows and 13 columns. Let's analyse the fields that we have now.

| S.No | Field                  | Description                                                 |
|-----------------|-----------------|--------------------------------------|
| 1    | Date                   | Day-Month-Year of when the statistic was recorded           |
| 2    | Province               | Name of Province in Thailand                                |
| 3    | Region                 | Name of Region to which the Province belongs to in Thailand |
| 4    | Month                  | Month of when statistic was recorded                        |
| 5    | Year                   | Year of when statistic was recorded                         |
| 6    | Ratio Tourist Stay     | Ratio of tourists who stayed overnight in the Province      |
| 7    | No Tourist Stay        | Number of tourists who stayed overnight in the Province     |
| 8    | No Tourist All         | Number of Domestic tourists who visited the Province        |
| 9    | No Tourist Thai        | Number of Thai tourists who visited the Province            |
| 10   | No Tourist Foreign     | Number of Foreign tourists who visited the Province         |
| 11   | Revenue All (in K)     | Revenue generated by tourism industry in the Province       |
| 12   | Revenue Thai (in K)    | Revenue generated by Thai tourists in the Province          |
| 13   | Revenue Foreign (in K) | Revenue generated by Foreign tourists in the Province       |

We can view the summary statistics of these newly exposed fields using the code chunk below.

```{r}
summary(tourism)
```

We can also perform exploratory data analysis using the code chunk below. By plotting histograms, we can easily identify the overall distribution of the data values.

```{r}
ggplot(data=tourism, 
       aes(x=`ratio_tourist_stay`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")
```

From the above plot, we can see that majority of the ratios are concentrated between 25% and 75%. The highest frequency appears around the 50% mark, indicating that a significant portion of tourists tend to stay overnight about half the time. However, this distribution tails off towards the extremes (near 100%), suggesting that fewer tourists stay overnight very frequently.

### 3.2 Boundary Data

Likewise, we can run the glimpse() function on the boundaries data for some quick insights.

```{r}
glimpse(boundaries)
```

The raw boundaries data has 77 rows and 17 columns. This data contains the geospatial information we require for our analysis.

Now, we will perform following actions using the code chunk below:

-   Exclude fields that contain text in thai language - ADM1_TH, ADM1ALT1TH, ADM1ALT2TH, ADM0_TH

-   Exclude fields that contain only one value - ADM1_REF, ADM1ALT1EN, ADM1ALT2EN, ADM0_EN, ADM0_PCODE, date, validOn, validTo

-   Exclude unnecessary fields that we will not use in our analysis - Shape_Leng, Shape_Area, ADM1_PCODE

-   Rename fields to a more appropriate name

```{r}
boundaries <- boundaries %>%
  select(3, 17) %>%
  rename(province = ADM1_EN)
```

We also want to keep the geometry field as a polygon instead of a multipolygon object. For this, we will first cast the geometry field into a polygon type, and then merge the polygons for each province into a single polygon.

```{r}
#|eval: false
boundary <- boundaries %>%
  group_by(province) %>%
  summarise(geometry = st_union(geometry))

boundary$geometry <- st_cast(boundary$geometry, "POLYGON")

boundary <- st_sf(boundary,
                  geometry = st_geometry(boundary))

write_rds(boundary, "data/rds/boundary.rds")
```

The code chunk below will be used to import the saved boundary.rds into R environment.

```{r}
boundary <- read_rds("data/rds/boundary.rds")
```

Let's take a look at the cleaned up tourism data set:

```{r}
glimpse(boundary)
```

The updated tourism data has 77 rows and 2 columns. Let's analyse the fields that we have now.

| S.No | Field    | Description                                              |
|------|----------|----------------------------------------------------------|
| 1    | Province | Name of Province in Thailand                             |
| 2    | Geometry | Polygon object that represents each Province in Thailand |


We can use qtm() to have a quick visual representation of the boundary data, allowing us to confirm that the geometries and province names are correct,

```{r}
qtm(boundary, fill = "province")
```

### 3.3 Creating Time Series Cube (Month)

We will first group the tourism data by months before creating the spacetime object for monthly data.

```{r}
#|eval: false
tourismMonthly <- tourism %>%
  group_by(province, month) %>%
  summarise(across(c("ratio_tourist_stay", "no_tourist_stay", "no_tourist_all", "no_tourist_thai",
                      "no_tourist_foreign", "revenue_all_K", "revenue_thai_K", "revenue_foreign_K"),
                    mean,
                    na.rm = TRUE),
            .groups = 'drop')
write_rds(tourismMonthly, "data/rds/tourismMonthly.rds")
```

The code chunk below will be used to import the saved tourismMonthly.rds into R environment.

```{r}
tourismMonthly <- read_rds("data/rds/tourismMonthly.rds")
```

We will then create a spatio-temporal object using the spacetime() function of sfdep. We will specify the following properties:

-   the data, which is the tourismMonthly data.frame object
-   the geometry, which is the boundary sf object
-   the location identifiers, which is the province
-   the time column, which is month

```{r}
#|eval: false
tourismMonthlyST <- spacetime(tourismMonthly, 
                              boundary,
                              .loc_col = "province",
                              .time_col = "month")
write_rds(tourismMonthlyST, "data/rds/tourismMonthlyST.rds")
```

The code chunk below will be used to import the saved tourismMonthlyST.rds into R environment.

```{r}
tourismMonthlyST <- read_rds("data/rds/tourismMonthlyST.rds")
```

We can use is_spacetime_cube() of sfdep package to verify if tourismMonthlyST is indeed a space-time cube object.

```{r}
is_spacetime_cube(tourismMonthlyST)
```

The TRUE return confirms that tourismMonthlyST is indeed a space-time cube.

### 3.4 Creating Time Series Cube (Year)

Similarly, we will group the tourism data by years before creating the spacetime object for yearly data.

```{r}
#|eval: false
tourismYearly <- tourism %>%
  group_by(province, year) %>%
  summarise(across(c("ratio_tourist_stay", "no_tourist_stay", "no_tourist_all", "no_tourist_thai",
                      "no_tourist_foreign", "revenue_all_K", "revenue_thai_K", "revenue_foreign_K"),
                    mean,
                    na.rm = TRUE),
            .groups = 'drop')
write_rds(tourismYearly, "data/rds/tourismYearly.rds")
```

The code chunk below will be used to import the saved tourismYearly.rds into R environment.

```{r}
tourismYearly <- read_rds("data/rds/tourismYearly.rds")
```

We will then create a spatio-temporal object using the spacetime() function of sfdep. We will specify the following properties:

-   the data, which is the tourismYearly data.frame object
-   the geometry, which is the boundary sf object
-   the location identifiers, which is the province
-   the time column, which is year

```{r}
#|eval: false
tourismYearlyST <- spacetime(tourismYearly, 
                              boundary,
                              .loc_col = "province",
                              .time_col = "year")
write_rds(tourismYearlyST, "data/rds/tourismYearlyST.rds")
```

The code chunk below will be used to import the saved tourismYearlyST.rds into R environment.

```{r}
tourismYearlyST <- read_rds("data/rds/tourismYearlyST.rds")
```

We can use is_spacetime_cube() of sfdep package to verify if tourismYearlyST is indeed a space-time cube object.

```{r}
is_spacetime_cube(tourismYearlyST)
```

The TRUE return confirms that tourismYearlyST is indeed a space-time cube.

### 3.5 Performing Relational Join

We need to combine both the geospatial data and the aspatial data into one. This will be performed using the left_join function of dplyr package. The boundary data will be used as the base data object, and the tourism data will be used as the join table.

The code chunk below is used to perform the task. The unique identifier that is used to join both data objects are province.

```{r}
#|eval: false
tourismBoundaries <- left_join(boundary, 
                               tourism, 
                               by=c("province"="province"))
tourismBoundariesSF <- st_sf(tourismBoundaries,
                             geometry = st_geometry(tourismBoundaries))
write_rds(tourismBoundariesSF, "data/rds/tourismBoundariesSF.rds")
```

The code chunk below will be used to import the saved tourismBoundariesSF.rds into R environment.

```{r}
tourismBoundariesSF <- read_rds("data/rds/tourismBoundariesSF.rds")
```

Note that no new output data has been created. Instead, the data fields from tourism data frame are now updated into the data frame of boundaries. Let's take a quick look at this joined data using the code chunk below.

```{r}
glimpse(tourismBoundariesSF)
```

The joined tourismBoundariesSF data has 3,458 rows and 14 columns. We can now perform exploratory data analysis using this joined data.

To have a quick look at the distribution of average ratio of tourists who stayed overnight at Thailand at Province level for the year 2023, a choropleth map will be prepared using the code chunk below.

```{r}
#|eval: false
tourismBoundaries2023 <- tourismBoundariesSF %>%
  filter(year == 2023) %>%
  group_by(province) %>%
  summarize(ratio_tourist_stay = mean(`ratio_tourist_stay`, na.rm = TRUE))
write_rds(tourismBoundaries2023, "data/rds/tourismBoundaries2023.rds")
```

The code chunk below will be used to import the saved tourismBoundaries2023.rds into R environment.

```{r}
tourismBoundaries2023 <- read_rds("data/rds/tourismBoundaries2023.rds")
ggplot(data = tourismBoundaries2023) +
  geom_sf(aes(fill = `ratio_tourist_stay`),
          color = NA) +
  scale_fill_viridis_c(option = "plasma",
                       name = "Ratio Tourist Stay") +
  labs(title = "Ratio of Tourists Who Stayed Overnight in 2023",
       subtitle = "Average Ratio per Province") +
  theme_minimal()
```

The choropleth map visualizes the average ratio of tourists who stayed overnight across the difference provinces in Thailand for 2023. The color of darker purple indicates lower ratios, while bright yellow represents high ratios. This allows us to easily identify regions with varying tourist overnight stays ratios.

## 4.0 Global Spatial Autocorrelation Analysis

We will now proceed to compute global spatial autocorrelation statistics and perform spatial complete randomness test for global spatial autocorrelation.

We first need to construct a spatial weights of the study area. These spatial weights will be used to define the neighbourhood relationships between the provinces in the study area.

The code chunk below is used to compute the contiguity weight matrices for the study area. The poly2nb() function of spdep 

## Local Spatial Autocorrelation Analysis

xx

## Emerging Hot Spot Analysis

xx
